{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b92845b85f289ba795c8c8f7117526abe073d0"
   },
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "abb7e3c30b8a412a50c6b451c49939e3cf4bc11b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "#import spacy\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "import os \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# cross validation and metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a4ff5590a6f152dc1bec5aeca79aef10218f7de"
   },
   "source": [
    "### Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "deee49df5ca1c4413f71677939e26aa1ff784e44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 750 # max number of words in a question to use\n",
    "batch_size = 512 # how many samples to process at once\n",
    "n_epochs = 5 # how many times to iterate over all samples\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "SEED = 10\n",
    "debug = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us need band together apart nevertrump promote...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bain life drive cash point shop change pound c...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clearly appreciate sub-harmonics -one</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly know i'm unhappy time want stop itnev...</td>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep cooties ni close eyes dream i'm awake we...</td>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  emotion\n",
       "0  us need band together apart nevertrump promote...       0    anger\n",
       "1  bain life drive cash point shop change pound c...       0    anger\n",
       "2              clearly appreciate sub-harmonics -one       1      joy\n",
       "3  honestly know i'm unhappy time want stop itnev...       3  sadness\n",
       "4  sleep cooties ni close eyes dream i'm awake we...       3  sadness"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5051, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0\n",
       "target     0\n",
       "emotion    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"len\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"len\"].\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.len.quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Y Column\n",
    "We are only going to be classifying conditions for which the count of reviews are more than 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "anger      2118\n",
       "joy        1163\n",
       "sadness    1325\n",
       "optimism    445"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count_df = data[[\"text\",\"emotion\"]].groupby(\"emotion\").aggregate({\"text\":\"count\"}).reset_index().sort_values(\"text\",ascending=False)\n",
    "count_df = pd.DataFrame.from_dict(Counter(data[\"emotion\"]), orient=\"index\", columns=[\"count\"])\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'sadness', 'optimism'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_conditions = count_df.index.values\n",
    "target_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=count_df, x=count_df.index, y=\"count\")\n",
    "plt.title(\"Bar plot showing distribution of classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', x)\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emotion</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us need band together apart nevertrump promote...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bain life drive cash point shop change pound c...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clearly appreciate sub-harmonics -one</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly know i'm unhappy time want stop itnev...</td>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep cooties ni close eyes dream i'm awake we...</td>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  emotion  len\n",
       "0  us need band together apart nevertrump promote...       0    anger   65\n",
       "1  bain life drive cash point shop change pound c...       0    anger   74\n",
       "2              clearly appreciate sub-harmonics -one       1      joy   37\n",
       "3  honestly know i'm unhappy time want stop itnev...       3  sadness   52\n",
       "4  sleep cooties ni close eyes dream i'm awake we...       3  sadness   72"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Clean numbers\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: clean_numbers(x))\n",
    "\n",
    "# lower and stopwords removal\n",
    "data[\"text\"] = data[\"text\"].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stopwords))\n",
    "\n",
    "# lower the text\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'sadness', 'optimism'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(data[\"text\"], data[\"emotion\"],\n",
    "                                                    stratify=data[\"emotion\"], \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "63cb21525251b060aeb309e7be4b48772f8720f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (3788,)\n",
      "Test shape :  (1263,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape : \",train_X.shape)\n",
    "print(\"Test shape : \",test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train_y.values)\n",
    "test_y = le.transform(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'optimism', 'sadness'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5c51a8329d569d13b9f0369ebb98ca8e2e55440"
   },
   "source": [
    "### Load Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file=\"glove/glove.42B.300d.txt\"):\n",
    "    \"\"\"Load the glove word vectors\"\"\"\n",
    "    word_vectors = {}\n",
    "    with open(glove_file) as f:\n",
    "        for line in f:\n",
    "            #print(line)\n",
    "            split = line.split()\n",
    "            #print(split[0])\n",
    "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_matrix(pretrained, word_counts, emb_size = 50):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_counts) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_counts:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = load_glove_vectors()\n",
    "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'UNK'], dtype='<U3')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
    "\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = 'glove/glove.42B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    nb_words = min(max_features, len(word_index)+1)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_vector = embeddings_index.get(word.capitalize())\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "6a5f4502324d369ff6faa3692accee4f8a233005",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gundruke/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54354/2561525244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_54354/1447459646.py\u001b[0m in \u001b[0;36mload_glove\u001b[0;34m(word_index)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mall_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0memb_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.005838499\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.48782197\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
    "\n",
    "if debug:\n",
    "    embedding_matrix = np.random.randn(120000,300)\n",
    "else:\n",
    "    embedding_matrix = load_glove(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49911/3970142331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_49911/1447459646.py\u001b[0m in \u001b[0;36mload_glove\u001b[0;34m(word_index)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mall_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0memb_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.005838499\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.48782197\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "embedding_matrix = load_glove(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "aa6a41607b804d76a2ddc530c912b5673bcd2423"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49911/1275149652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a78496e4d88d8fb351cdf26d02f1554821ed445"
   },
   "source": [
    "## Pytorch Model - TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        filter_sizes = [1,2,3,5]\n",
    "        num_filters = 36\n",
    "        n_classes = len(le.classes_)\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = x.unsqueeze(1)  \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  \n",
    "        logit = self.fc1(x) \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0da30e2afce23b753796f3045b44ce91a07e4303"
   },
   "source": [
    "## Train TextCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "6a5afb54f70a29808af19946ba08ef971d194e46"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49911/1747016647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_49911/3035711708.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 6\n",
    "model = CNN_Text()\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "model.cuda()\n",
    "\n",
    "# Load train and test in CUDA Memory\n",
    "x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
    "y_train = torch.tensor(train_y, dtype=torch.long).cuda()\n",
    "x_cv = torch.tensor(test_X, dtype=torch.long).cuda()\n",
    "y_cv = torch.tensor(test_y, dtype=torch.long).cuda()\n",
    "\n",
    "# Create Torch datasets\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Set model to train configuration\n",
    "    model.train()\n",
    "    avg_loss = 0.  \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Predict/Forward Pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "    \n",
    "    # Set model to validation configuration -Doesn't get trained here\n",
    "    model.eval()        \n",
    "    avg_val_loss = 0.\n",
    "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        # keep/store predictions\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
    "    \n",
    "    # Check Accuracy\n",
    "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'textcnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d1b3fc0c8bc59f91a203adcf3dbd9d89759c8df"
   },
   "outputs": [],
   "source": [
    "def plot_graph(epochs):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.title(\"Train/Validation Loss\")\n",
    "    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n",
    "    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "y_true = [le.classes_[x] for x in test_y]\n",
    "y_pred = [le.classes_[x] for x in val_preds.argmax(axis=1)]\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    y_true, \n",
    "    y_pred,\n",
    "    figsize=(12,12),x_tick_rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model - BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = 64\n",
    "        drp = 0.1\n",
    "        n_classes = len(le.classes_)\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size*4 , 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #rint(x.size())\n",
    "        h_embedding = self.embedding(x)\n",
    "        #_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        avg_pool = torch.mean(h_lstm, 1)\n",
    "        max_pool, _ = torch.max(h_lstm, 1)\n",
    "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "model = BiLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "model.cuda()\n",
    "\n",
    "# Load train and test in CUDA Memory\n",
    "x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
    "y_train = torch.tensor(train_y, dtype=torch.long).cuda()\n",
    "x_cv = torch.tensor(test_X, dtype=torch.long).cuda()\n",
    "y_cv = torch.tensor(test_y, dtype=torch.long).cuda()\n",
    "\n",
    "# Create Torch datasets\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Set model to train configuration\n",
    "    model.train()\n",
    "    avg_loss = 0.  \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Predict/Forward Pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "    \n",
    "    # Set model to validation configuration -Doesn't get trained here\n",
    "    model.eval()        \n",
    "    avg_val_loss = 0.\n",
    "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        # keep/store predictions\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
    "    \n",
    "    # Check Accuracy\n",
    "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'bilstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "y_true = [le.classes_[x] for x in test_y]\n",
    "y_pred = [le.classes_[x] for x in val_preds.argmax(axis=1)]\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    y_true, \n",
    "    y_pred,\n",
    "    figsize=(12,12),x_tick_rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy : Predict A Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(x):    \n",
    "    # lower the text\n",
    "    x = x.lower()\n",
    "    # Clean the text\n",
    "    x =  clean_text(x)\n",
    "    # Clean numbers\n",
    "    x =  clean_numbers(x)\n",
    "    # Clean Contractions\n",
    "    x = replace_contractions(x)\n",
    "    # tokenize\n",
    "    x = tokenizer.texts_to_sequences([x])\n",
    "    # pad\n",
    "    x = pad_sequences(x, maxlen=maxlen)\n",
    "    # create dataset\n",
    "    x = torch.tensor(x, dtype=torch.long).cuda()\n",
    "\n",
    "    pred = model(x).detach()\n",
    "    pred = F.softmax(pred).cpu().numpy()\n",
    "\n",
    "    pred = pred.argmax(axis=1)\n",
    "\n",
    "    pred = le.classes_[pred]\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['review'].values[20]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
