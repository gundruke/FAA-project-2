{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loader(file, is_number = False):\n",
    "    data = []\n",
    "    with open(file, encoding=\"utf8\") as my_file:\n",
    "        data = my_file.read().splitlines()\n",
    "    if is_number:\n",
    "        data = [int(i) for i in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = loader(\"data/test_text.txt\")\n",
    "test_labels = loader(\"data/test_labels.txt\", True)\n",
    "val_data = loader(\"data/val_text.txt\")\n",
    "val_labels = loader(\"data/val_labels.txt\", True)\n",
    "train_data = loader(\"data/train_text.txt\")\n",
    "train_labels = loader(\"data/train_labels.txt\", True)\n",
    "mappings = {0:\"anger\", 1:\"joy\", 2:\"optimism\",3:\t\"sadness\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"text\":test_data, \"label\":test_labels, \"emotion\":[mappings[i] for i in test_labels]})\n",
    "val = pd.DataFrame({\"text\":val_data, \"label\":val_labels, \"emotion\":[mappings[i] for i in val_labels]})\n",
    "train = pd.DataFrame({\"text\":train_data, \"label\":train_labels, \"emotion\":[mappings[i] for i in train_labels]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/roberta_en_cased_preprocess/1\")\n",
    "\n",
    "bert_model = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/roberta_en_cased_L-24_H-1024_A-16/1\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def build_classifier_model(number_classes):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(number_classes, activation='softmax', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "def execute_model(X_train, y_train, X_test, y_test, epochs):\n",
    "\n",
    "    #we use label encoding to convert text labels to numeric, we go from ineffective -> 0 for example\n",
    "\n",
    "\n",
    "    #we then need to convert the values to tensors, ensuring that the values are converted to strings.\n",
    "    X_train = tf.convert_to_tensor(X_train.map(str))\n",
    "    y_train = tf.convert_to_tensor(y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test.map(str))\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "    #extract the number of classes\n",
    "    number_classes = len(set(y_train.numpy()))\n",
    "\n",
    "    #build the model\n",
    "    classifier_model = build_classifier_model(number_classes)\n",
    "    #we use adam optimizer, as it is an industry standard, and the loss as sparse categorical crossentropy, as our labels are not one-hot encoded.\n",
    "    classifier_model.compile(optimizer=\"adam\",\n",
    "                            loss='sparse_categorical_crossentropy',\n",
    "                            metrics=['acc'])\n",
    "\n",
    "    #we can then train the model\n",
    "    print(f'Training model:')\n",
    "    history = classifier_model.fit(X_train, y_train,\n",
    "                               epochs=epochs)\n",
    "\n",
    "    #evaluate the model\n",
    "    print(\"Evaluating accuracy:\")\n",
    "    loss, accuracy = classifier_model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    #predict for the test data\n",
    "    prediction = classifier_model.predict(X_test)\n",
    "    y_pred = []\n",
    "    for class_pos in prediction.argmax(axis=1):\n",
    "        y_pred.append(class_pos)\n",
    "\n",
    "\n",
    "    #show the f1 score and confusion matrix\n",
    "    print(f\"weighted f1-score:{f1_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    fig = sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "    fig.set(xlabel='Predicted', ylabel='Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train.text, train.label\n",
    "X_test, y_test = test.text, test.label\n",
    "execute_model(X_train, y_train, X_test, y_test, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
