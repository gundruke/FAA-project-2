{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Text Classification\n",
    "\n",
    "We are going to predict item ratings based on customer reviews bsed on this dataset from Kaggle:\n",
    "https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: setuptools in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gundruke/anaconda3/envs/pytorch/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3631, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user happy bday Ruth, hope you have an amazin...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banger sit in 2013 reason why we great doings ...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height of irritation when a person makes a hil...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#internationaldayofpeace Want peace,prepare fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oi @user you've absolutely fucking killed me.....</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target emotion\n",
       "0  @user happy bday Ruth, hope you have an amazin...       1     joy\n",
       "1  Banger sit in 2013 reason why we great doings ...       1     joy\n",
       "2  Height of irritation when a person makes a hil...       0   anger\n",
       "3  #internationaldayofpeace Want peace,prepare fo...       0   anger\n",
       "4  Oi @user you've absolutely fucking killed me.....       1     joy"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data\n",
    "emotions = pd.read_csv(\"data/emotions.csv\")\n",
    "print(emotions.shape)\n",
    "emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tok = spacy.load(\"en_core_web_sm\")\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in emotions.iterrows():\n",
    "    counts.update(tokenize(row[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 9190),\n",
       " ('user', 2259),\n",
       " ('  ', 1927),\n",
       " ('i', 1756),\n",
       " ('the', 1659),\n",
       " ('to', 1326),\n",
       " ('a', 1180),\n",
       " ('and', 994),\n",
       " ('you', 820),\n",
       " ('is', 817)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 8824\n",
      "num_words after: 3849\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>emotion</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user happy bday Ruth, hope you have an amazin...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>[[2, 3, 4, 5, 1, 2, 6, 7, 8, 9, 10, 11, 2, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banger sit in 2013 reason why we great doings ...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>[[1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 1, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height of irritation when a person makes a hil...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>[[26, 27, 28, 29, 30, 31, 32, 30, 33, 1, 34, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#internationaldayofpeace Want peace,prepare fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>[[2, 37, 38, 39, 1, 22, 40, 2, 41, 42, 43, 44,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oi @user you've absolutely fucking killed me.....</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>[[1, 2, 3, 7, 46, 47, 48, 49, 50, 15, 51, 52, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target emotion  \\\n",
       "0  @user happy bday Ruth, hope you have an amazin...       1     joy   \n",
       "1  Banger sit in 2013 reason why we great doings ...       1     joy   \n",
       "2  Height of irritation when a person makes a hil...       0   anger   \n",
       "3  #internationaldayofpeace Want peace,prepare fo...       0   anger   \n",
       "4  Oi @user you've absolutely fucking killed me.....       1     joy   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 1, 2, 6, 7, 8, 9, 10, 11, 2, 12,...  \n",
       "1  [[1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 1, 22...  \n",
       "2  [[26, 27, 28, 29, 30, 31, 32, 30, 33, 1, 34, 3...  \n",
       "3  [[2, 37, 38, 39, 1, 22, 40, 2, 41, 42, 43, 44,...  \n",
       "4  [[1, 2, 3, 7, 46, 47, 48, 49, 50, 15, 51, 52, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[\"encoded\"] = emotions[\"text\"].apply(lambda x: np.array(encode_sentence(x,vocab2index ), dtype=object))\n",
    "emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"emotion\", data=emotions)\n",
    "ax.set_title(\"Value count of each label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(emotions[\"encoded\"])\n",
    "y = list(emotions[\"target\"])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with fixed length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fixed =  LSTM_fixed_len(vocab_size, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.513, val loss 1.463, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.296, val loss 1.287, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.273, val loss 1.271, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.268, val loss 1.264, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.265, val loss 1.260, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.264, val loss 1.262, val accuracy 0.428, and val rmse 1.757\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.305, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.267, val loss 1.260, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.268, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.266, val loss 1.267, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.263, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.264, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.277, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.271, val loss 1.265, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.267, val loss 1.259, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.264, val loss 1.264, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.263, val loss 1.258, val accuracy 0.428, and val rmse 1.757\n",
      "train loss 1.263, val loss 1.259, val accuracy 0.428, and val rmse 1.757\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fixed, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with variable length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_variable_input(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_variable_input(vocab_size, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.456, val loss 1.898, val accuracy 0.224, and val rmse 2.138\n",
      "train loss 1.146, val loss 1.218, val accuracy 0.488, and val rmse 1.554\n",
      "train loss 0.842, val loss 1.211, val accuracy 0.546, and val rmse 1.519\n",
      "train loss 0.625, val loss 1.368, val accuracy 0.568, and val rmse 1.459\n",
      "train loss 0.483, val loss 1.465, val accuracy 0.583, and val rmse 1.408\n",
      "train loss 0.393, val loss 1.604, val accuracy 0.565, and val rmse 1.426\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.528, val loss 1.675, val accuracy 0.576, and val rmse 1.403\n",
      "train loss 0.318, val loss 1.693, val accuracy 0.590, and val rmse 1.419\n",
      "train loss 0.264, val loss 1.697, val accuracy 0.575, and val rmse 1.394\n",
      "train loss 0.230, val loss 1.783, val accuracy 0.575, and val rmse 1.392\n",
      "train loss 0.218, val loss 1.875, val accuracy 0.583, and val rmse 1.369\n",
      "train loss 0.175, val loss 1.954, val accuracy 0.572, and val rmse 1.389\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.214, val loss 2.064, val accuracy 0.587, and val rmse 1.348\n",
      "train loss 0.178, val loss 2.146, val accuracy 0.558, and val rmse 1.454\n",
      "train loss 0.161, val loss 2.193, val accuracy 0.587, and val rmse 1.372\n",
      "train loss 0.132, val loss 2.204, val accuracy 0.591, and val rmse 1.405\n",
      "train loss 0.130, val loss 2.248, val accuracy 0.596, and val rmse 1.352\n",
      "train loss 0.114, val loss 2.348, val accuracy 0.571, and val rmse 1.423\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
